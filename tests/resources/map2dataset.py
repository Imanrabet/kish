import os
import json
import gzip
import random
import argparse
import re

'''
Convert a map file generated by harvester into a dataset file descriptor that
can be loaded in KISH

input: jsonl file map.json

{
    "id": "03582f70-2463-45e6-af96-4a3dc78e87c3", 
    "DOI": "10.1080/10486801.2021.1878511", 
    "oaLink": "https://www.tandfonline.com/doi/pdf/10.1080/10486801.2021.1878511?needAccess=true", 
    "pdf_file_path": "03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.pdf", 
    "json_metadata_file_path": "03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.json"
}
...

(note above is jsonl, one json per line, it has been reformatted for reading purposes)

output: json 

{
    "documents": [
        {
            "id": "03582f70-2463-45e6-af96-4a3dc78e87c3",
            "doi": "10.1080/10486801.2021.1878511",
            "full_text_url": "https://www.tandfonline.com/doi/pdf/10.1080/10486801.2021.1878511?needAccess=true",
            "full_text_pdf_uri": "03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.pdf",
            "full_text_tei_uri": "03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.tei.xml",
            "texts": []
        },
        ...
    ]
}

second, if resources files exist and contain the extracted software/dataset mentions (as *.software.json file), we can inject the 
pre-annotation into the dataset file, e.g. if 

03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.software.json
03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.dataset.json

exist, we access the file and enrich output:

{
    "documents": [
        {
            "id": "03582f70-2463-45e6-af96-4a3dc78e87c3",
            "doi": "10.1080/10486801.2021.1878511",
            "full_text_url": "https://www.tandfonline.com/doi/pdf/10.1080/10486801.2021.1878511?needAccess=true",
            "full_text_pdf_uri": "03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.pdf",
            "full_text_tei_uri": "03/58/2f/70/03582f70-2463-45e6-af96-4a3dc78e87c3/03582f70-2463-45e6-af96-4a3dc78e87c3.tei.xml",
            "texts": [
                {
                    "text": "Image preprocessing was carried out using SPM5 (http://www.fil.ion.ucl.ac.uk/spm). ",
                    "entity_spans": [
                        {
                            "start": 42,
                            "end": 46,
                            "type": "software",
                            "rawForm": "SPM5",
                            "id": "PMC3932086-software-100",
                            "boundingBoxes": [{"p": 6, "x": 184.644, "y": 193.933, "w": 28.812857142857144, "h": 7.7739}],
                            "excerpt_id": "__6nvVVpe"
                        },
                        {
                            "start": 48,
                            "end": 80,
                            "type": "url",
                            "rawForm": "http://www.fil.ion.ucl.ac.uk/spm",
                            "id": "#PMC3932086-software-100",
                            "boundingBoxes": [{"p": 6, "x": 129.485, "y": 122.186, "w": 28.812857142857144, "h": 7.7739}],
                            "excerpt_id": "__6nvVVpe"
                        }
                    ],
                    "full_context": "Image preprocessing was carried out using SPM5 (http://www.fil.ion.ucl.ac.uk/spm)."
                },
                ...
            ]
        },
        ...
    ]
}

'''

def convert(json_map_file: str, dataset_json_path: str):
    if json_map_file.endswith(".gz"):
        f = gzip.open(json_map_file,'rb')
    else:
        f = open(json_map_file, "r")

    json_map_dir = os.path.dirname(json_map_file)
    new_documents = []

    for line in f:
        document = json.loads(line)
        if "pdf_file_path" not in document:
            continue

        new_document = {}
        new_document["id"] = document["id"]
        new_document["doi"] = document["DOI"]
        new_document["full_text_url"] = document["oaLink"]
        new_document["full_text_pdf_uri"] = document["pdf_file_path"]
        new_document["full_text_tei_uri"] = document["pdf_file_path"].replace(".pdf", ".tei.xml")
        new_document["texts"] = []

        # for the indicated sentence contexts, we retrieve the original TEI identifier and bounding boxes
        # they can be accessed in the JSON file with extension .tei.json if present along the other files
        tei_structure_file = os.path.join(json_map_dir, document["pdf_file_path"].replace(".pdf", ".tei.json"))

        print(tei_structure_file)
        map_sentence_id = {}
        if os.path.exists(tei_structure_file) and os.path.isfile(tei_structure_file): 
            with open(tei_structure_file, encoding='utf-8') as f:
                tei_structure_json = json.load(f)
                main_structures = ["abstract", "body_text"]
                for main_structure in main_structures:
                    if main_structure in tei_structure_json:
                        for text_item in tei_structure_json[main_structure]:
                            local_text = text_item["text"] if "text" in text_item else None
                            local_id = text_item["id"] if "id" in text_item else None
                            local_bounding_boxes = text_item["boundingBoxes"] if "boundingBoxes" in text_item else None
                            local_signature = string_signature(local_text)
                            if local_signature in map_sentence_id and map_sentence_id[local_signature] != None:
                                map_sentence_id[local_signature] = map_sentence_id[local_signature].append([local_id, local_bounding_boxes, local_text])
                            else:
                                map_sentence_id[local_signature]= [ [local_id, local_bounding_boxes, local_text] ]

        # read the software mention file if present
        software_annotation_file = os.path.join(json_map_dir, document["pdf_file_path"].replace(".pdf", ".software.json"))

        software_fields = ["software-name", "url", "version", "publisher", "language"]

        if os.path.exists(software_annotation_file) and os.path.isfile(software_annotation_file): 
            with open(software_annotation_file, encoding='utf-8') as f:
                software_annotation_json = json.load(f)
                if "mentions" in software_annotation_json:
                    current_text = None
                    text_entry = None
                    for mention in software_annotation_json["mentions"]:
                        if "type" in mention and mention["type"] == "software":
                            if "context" not in mention:
                                local_text = None
                            else:
                                local_text = mention["context"]
                            if current_text == None or current_text != local_text:
                                if current_text != None and current_text != local_text:
                                    new_document["texts"].append(text_entry)
                                current_text = local_text
                                text_entry = {}
                                text_entry["text"] = current_text
                                text_entry["entity_spans"] = []

                            if "text" in text_entry:
                                local_signature = string_signature(text_entry["text"])
                                if local_signature in map_sentence_id:
                                    text_entries = map_sentence_id[local_signature]
                                    if text_entries != None and len(text_entries) != 0:
                                        if len(text_entries) == 1:
                                            text_entrie = text_entries[0]
                                            text_entry["id"] = text_entrie[0]
                                            text_entry["boundingBoxes"] = text_entrie[1]
                                            text_entry["text"] = text_entrie[2]
                                        else:
                                            # we need to select "best" match based on the coordinates

                                            for text_entrie in text_entries:
                                                text_entry["id"] = text_entrie[0]
                                                text_entry["boundingBoxes"] = text_entrie[1]
                                                text_entry["text"] = text_entrie[2]
                                                break
                            
                            if "text" not in text_entry or text_entry["text"] == None:
                                continue

                            for field in software_fields:
                                if field in mention:
                                    local_annotation = {}
                                    if field == "software-name":
                                        local_annotation["type"] = "software"
                                    else:
                                        local_annotation["type"] = field

                                    if "offsetStart" not in mention[field]:
                                        # this is a propagated attribute not present on the local text
                                        continue

                                    local_annotation["start"] = mention[field]["offsetStart"]
                                    local_annotation["end"] = mention[field]["offsetEnd"]
                                    local_annotation["rawForm"] = mention[field]["rawForm"]

                                    # we re-adjust the offsets because the sentence from Grobid are more normalized (e.g. hyphen,
                                    # no remaining end of line), so possibly less characters
                                    shift = len(current_text) - len(text_entry["text"])
                                    if shift > 0:
                                        ind = text_entry["text"].find(local_annotation["rawForm"], local_annotation["start"]-shift)
                                        if ind != -1:
                                            local_annotation["start"] = ind
                                            local_annotation["end"] = ind+len(local_annotation["rawForm"])
                                                            
                                    local_annotation["boundingBoxes"] = mention[field]["boundingBoxes"]
                                    #local_annotation["id"] = ""
                                    # typical id with annotation is as follow: "id": "PMC3932086-software-100"
                                    # we could generate it here, or skip
                                    text_entry["entity_spans"].append(local_annotation)

                            # reference marker annotations
                            if "references" in mention:
                                for reference in mention["references"]:
                                    if "offsetStart" not in reference:
                                        continue
                                    '''
                                    format for a reference marker is:
                                    {
                                        "label": "(Arnouts et al. 1999",
                                        "normalizedForm": "(Arnouts et al. 1999",
                                        "refKey": 2,
                                        "offsetStart": 21021,
                                        "offsetEnd": 21064,
                                        "boundingBoxes": [{
                                            "p": 5,
                                            "x": 143.686,
                                            "y": 651.141,
                                            "w": 148.41150000000002,
                                            "h": 8.797000000000025
                                        }, {
                                            "p": 5,
                                            "x": 50.74,
                                            "y": 663.595,
                                            "w": 23.7947,
                                            "h": 8.797000000000025
                                        }]
                                    }
                                    '''
                                    local_annotation = {}
                                    local_annotation["type"] = "reference"
                                    local_annotation["start"] = reference["offsetStart"]
                                    local_annotation["end"] = reference["offsetEnd"]
                                    local_annotation["rawForm"] = reference["label"]
                                    local_annotation["boundingBoxes"] = reference["boundingBoxes"]
                                    #local_annotation["id"] = ""
                                    # typical id with annotation is as follow: "id": "PMC3932086-software-100"
                                    # we could generate it here, or skip
                                    text_entry["entity_spans"].append(local_annotation)

                    # last text entry
                    if text_entry !=  None:
                        new_document["texts"].append(text_entry)

        # read the dataset mention file if present
        '''
        dataset_annotation_file = document["pdf_file_path"].replace(".pdf", ".dataset.json")

        if os.path.exists(dataset_annotation_file) and os.path.isfile(dataset_annotation_file): 
            dataset_annotation_json = json.load(software_annotation_file)
            if "mentions" in dataset_annotation_json:
                for mention in dataset_annotation_json["mentions"]:
                    if "type" in mention and mention["type"] == "dataset":
                        if "dataset-name" in mention:
        '''

        new_documents.append(new_document)

    f.close()

    new_corpus = {}
    new_corpus["documents"] = new_documents

    # create a single json output with the document entries ready for KISH loading
    with open(dataset_json_path, 'w') as outfile:
        json.dump(new_corpus, outfile, indent=4)

def string_signature(string):
    '''
    Generate a signature for a given string, which is a simplified version of the string
    '''
    if string == None: 
        return None
    result = re.sub(r'[^a-zA-Z0-9]', '', string)
    return result

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description = "Convert harvester map file into dataset description file for KISH")

    parser.add_argument('-j','--json', type=str, help='path to the JSON map file generated by the harvester', required=True)
    parser.add_argument("--output", type=str, 
        help="path where to generate the dataset description file for KISH")

    args = parser.parse_args()
    json_map_file = args.json
    dataset_json_path = args.output

    # check path and call methods
    if json_map_file is None or not os.path.isfile(json_map_file):
        print("error: the path to one of the JSON map file is not valid: ", json_map_file)
        exit(0)

    if not json_map_file.endswith(".json") and not json_map_file.endswith(".json.gz"):
        print("JSON map file  has invalid file extension: " + json_map_file)
        exit(0)

    convert(json_map_file, dataset_json_path)
